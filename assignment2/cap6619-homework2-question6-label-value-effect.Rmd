---
title: "CAP-6619 Homework 2, question 6 - effect of label value"
author: Christian Garbin
date: Fall 2018
note: This code follows the tidyverse styleguide http://style.tidyverse.org/
output: html_notebook
---

# Effect of label value in weight calculation

As a first step to answer question 6 in homerwork 2, I tried to reproduce the example used in class.

The accuracy values I was getting were significantly different from the ones we got in class.

Some of those differences may be related to different random values (the class examples do not set a
seed value - `set.seed()`).

However, after some experimentation, I noticed that I had set the class labels to 0 and 1. The class example used labels -1 and 1. After changing the labels to match the ones used in class I started to
get results that were closer to what we saw in class.

At this point I'm not able to explain the different results This notebook was created to show that
effect and perhaps revisit it later, when I have time to dig into the `neuralnet()` code.

# Setup the environment and constants

```{r error=TRUE, warning=TRUE}
# Always start with a clean environment to avoid subtle bugs
rm(list = ls())

# To get repeatable results with random numbers (easier to debug multiple runs)
# Note: only works when running the notebook from the top. When running cells individually,
# add this line to each cell.
set.seed(1234) 

setwd("~/fau/cap6619/assignments/assignment2")

# install.packages("pixmap")
library(pixmap)
library(gdata)

# What the class label column is called in the data frames
# This MUST match the name of the class label variable added to the data frame
CLASS_LABEL <- "class_label"
```

# Helper functions

Read images and adds label to them.

```{r error=TRUE, warning=TRUE}
#' Read image files matching pattern, add class label and return them as grey-scale data frame,
#' with the given class as the last element in the vectors.
#'
#' @param path_name Directory where the images are, relative to current directory.
#' @param file_pattern A pattern to identify the image files to load.
#' @param label The label to be used for these images.
#'
#' @return A data frame with one row for each image and one column for each pixel (converted to
#'         grey scale) and the given label as the last (rightmost) column.
load_images <- function(path_name, file_pattern, label) {
  # Get all file names matching the pattern
  files <- list.files(path = path_name, pattern = file_pattern, all.files = T, full.names = T)

  # Read all images
  images <- lapply(files, read.pnm, cellres = 1)

  # Debug: show the first image
  #cat("Image for class", label, "\n\n")
  #plot(images[[1]])

  # Transform image to grey scale vectors
  image_matrix <- images[[1]]@grey
  image_vector <- unmatrix(image_matrix, byrow = T)
  for (ii in 2:length(images)) {
    i.matrix <- images[[ii]]@grey
    i.vector <- unmatrix(i.matrix, byrow = T)
    image_vector <- rbind(image_vector, i.vector)
  }

  # Change to a data frame
  image_frame <- data.frame(image_vector)

  # Add class label (variable name must match constant for class label column name)
  number_of_images <- nrow(image_frame)
  class_label <- rep(label, number_of_images)
  image_frame <- cbind(image_frame, class_label)

  return(image_frame)
}
```

Create, train the neural network and calculate its prediction on the test data.

```{r error=TRUE, warning=TRUE}
#' Creates a neural net with the given layers, trains and tests it.
#'
#' @param training The trainig data frame, with the class label in the last column.
#' @param test The test data frame, with the class label in the last column.
#' @param layers A vector representing the network configuration, to be used for the \code{hidden}
#'   parameter of \code{neuralnet}.
#' @param rep The number of repetitions to be used during training, to be used for the \code{rep}
#'   parameter of \code{neuralnet}.
#'
#' @return Two sets of predicted class using the test data and the \code{compute} function, one set
#'   has the first repetition, the other has the best repetition (the one with the smallest error).
#'   The predicted class is returned as a continuous value, not categorical values.
#'
#' @section IMPORTANT
#' "Best" in this context is "smallest error for the *traninig data*". It doesn't mean the best
#' (smallest) error on the test data. To properly find the best repetition we need a more
#' sophisticated technique, e.g. cross-validation with folds. The code as is simply prevents us from
#' blindly picking the first repetition in all cases, improving the odds we are picking a better
#' one (compared to the first), but could have side effects (e.g. choose a model that overfits).
classify_faces <- function(training, test, layers, rep) {
  # install.packages("neuralnet")
  library(neuralnet)

  # To get repeatable results with random numbers
  set.seed(1234)

  class_label <- paste(CLASS_LABEL, "~ ", sep = " ")
  myform <- as.formula(paste(class_label, paste(names(training[!names(training) %in%
    CLASS_LABEL]), collapse = " + ")))

  classifier <- neuralnet(myform, training,
    hidden = layers, rep = rep, linear.output = FALSE,
    threshold = 0.1
  )

  class_index <- length(test)

  predicted_first <- compute(classifier, test[, -class_index])
  predicted_best <- compute(classifier, test[, -class_index],
    rep = which.min(classifier$result.matrix["error", ])
  )

  return(list(first = predicted_first$net.result, best = predicted_best$net.result))
}
```

Show results from the classification: accuracy and confusion matrix.

```{r error=TRUE, warning=TRUE}
#' Show the results from the classification (confusion matrix and accuracy).
#'
#' @param title A string to identify the results being shown.
#' @param test The test data frame, with the class label in the last column.
#' @param classification The results from the classification (as returned by \code{compute}).
#' @param class_a_label Label for one of the classes
#' @param class_b_label Label for the other class
show_results <- function(title, test, classification, class_a_label, class_b_label) {
  # Changes from continuous to categorical values
  predicted <- ifelse(classification > 0.5, class_a_label, class_b_label)

  # Extract the actual labels (assumes label is the last column in the test set)
  class_index <- length(test)
  actual <- test[, class_index]

  # Show confusion matrix and accuracy
  # As a reminder: TN <- t[1, 1], FP <- t[1, 2], FN <- t[2, 1], TP <- t[2, 2]
  t <- table(predicted, actual)
  accuracy <- (sum(diag(t))) / sum(t)

  # Debug code
  # Show classification, predicted value and actual value side by side
  # predicted_vs_actual <- cbind(classification, predicted, actual)
  # print(predicted_vs_actual)

  cat(title, "\n\n")
  print(t)
  cat("Accuracy: ", accuracy, "\n\n")
}
```

Split a data set into training and test set.

```{r error=TRUE, warning=TRUE}
#' Randomize a set and split it into a training and a test set.
#'
#' @param set The dataframe to be randomized
#' @param training_fraction How much of the dataframe should be used as training data
#'
#' @return A list with two dataframes, one for training, one for test.
split_data_set <- function(set, training_fraction) {
  # To get repeatable results with random numbers
  set.seed(1234)

  train_index <- sample(nrow(set), nrow(set) * training_fraction)
  training_set <- set[train_index, ]
  test_set <- set[-train_index, ]
  return(list(training = training_set, test = test_set))
}
```

# Experiment with different class labels

This section reproduces the example we saw in class (but note that results will not be exactly
the same because of differences in random values - the class examples didn't set a seed).

First it uses one set of class labels, then another.

The goal is to show how the choice of labels affects the results.

```{r error=TRUE, warning=TRUE}
#' Run the classification tasks with the given labels and report the results.
#'
#' @param class_a_label Label for one of the classes
#' @param class_b_label Label for the other class
run_experiment <- function(class_a_label, class_b_label) {
  class_a_images <- load_images("faces/fromclass/left", ".*\\.pgm", class_a_label)
  class_b_images <- load_images("faces/fromclass/right", ".*\\.pgm", class_b_label)
  all_images <- split_data_set(rbind(class_a_images, class_b_images), 0.6)
  training_set <- all_images$training
  test_set <- all_images$test

  results <- classify_faces(training_set, test_set, c(2), 100)
  show_results("Class example - one hidden layer, two neurons, first", test_set, results$first,
               class_a_label, class_b_label)
  show_results("Class example - one hidden layer, two neurons, best", test_set, results$best,
               class_a_label, class_b_label)

  results <- classify_faces(training_set, test_set, c(4, 3), 1000)
  show_results("Class example - two hidden layers, 4/3 neurons each, first", test_set, results$first,
               class_a_label, class_b_label)
  show_results("Class example - two hidden layers, 4/3 neurons each, best", test_set, results$best, 
               class_a_label, class_b_label)
  }
```

#### Labels 1 and -1

```{r error=TRUE, warning=TRUE}
run_experiment(1, -1)
```

#### Labels 1 and 0

```{r error=TRUE, warning=TRUE}
run_experiment(1, 0)
```
